{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: AJAY UGALE\n",
    "#### Student ID: S3940207\n",
    "\n",
    "Date: 02/10/2022\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "You should give a brief information of this assessment task here.\n",
    "\n",
    "<span style=\"color: red\"> Note that this is a sample notebook only. You will need to fill in the proper markdown and code blocks. You might also want to make necessary changes to the structure to meet your own needs. Note also that any generic comments written in this notebook are to be removed and replace with your own words.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os \n",
    "from collections import Counter\n",
    "\n",
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Job Advertisement Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...... Sections and code blocks on buidling different document feature represetations\n",
    "\n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using bag of words approach for generating count vectors </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_text = []\n",
    "global_title = []\n",
    "y = []\n",
    "\n",
    "# Regular expression to tokenize the job description\n",
    "def data_preprocessing(text):\n",
    "    reg = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "    filtered = [word for word in re.findall(reg, text.lower())]\n",
    "    with open(\"stopwords_en.txt\", \"r\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        # Remove the stopwords \n",
    "        stopwords = [line.replace('\\n', '') for line in stopwords]\n",
    "        filtered = [word for word in filtered if word not in stopwords]\n",
    "\n",
    "        # Find the word counts\n",
    "        output = np.unique(np.array(filtered), return_counts=True)\n",
    "        return output[0], output[1]\n",
    "\n",
    "\n",
    "def convert_dict(words, counts):\n",
    "    # Creaing a dictionary of vocabulary for easy data manipulation\n",
    "    vocab_dict = {}\n",
    "    output_dict = {}\n",
    "\n",
    "    # Read the vocabulary text\n",
    "    with open('vocab.txt') as f:\n",
    "        vocab = f.readlines()\n",
    "    vocab = [v.replace('\\n', '') for v in vocab]\n",
    "\n",
    "    for v in vocab:\n",
    "        word, count = v.split(':')\n",
    "        vocab_dict[word] = int(count)\n",
    "\n",
    "    for w, c in zip(words, counts):\n",
    "        if w in vocab_dict.keys():\n",
    "            output_dict[vocab_dict[w]] = c\n",
    "    # Sort the output dictionary according to key values\n",
    "    output_dict = dict(sorted(output_dict.items(), key=lambda x:x[0]))\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for branch in [branches for branches in os.listdir('./data') if branches!='.DS_Store']:\n",
    "    for jd in os.listdir(f'./data/{branch}'):\n",
    "        y.append(branch)\n",
    "        with open(os.path.join('./data', branch, jd), \"r\", encoding='utf-8') as f:\n",
    "            text_full = f.read()\n",
    "            # Fetch the job description from the file\n",
    "            text = text_full.split('Description: ', 1)[1]\n",
    "            # Fetch the title from the file\n",
    "            text_title = text_full.split('\\n')[0].split(\"Title: \")[1]\n",
    "            \n",
    "        words, counts = data_preprocessing(text)\n",
    "        words_title, counts_title = data_preprocessing(text_title)\n",
    "        \n",
    "        output_dict = convert_dict(words, counts)\n",
    "        output_dict_title = convert_dict(words_title, counts_title)\n",
    "        \n",
    "        global_title.append(output_dict_title)\n",
    "        \n",
    "        # Feteching the webindex\n",
    "        webindex = re.findall(r\"[0-9]+\",text_full.split('\\n')[1])\n",
    "        count_vectors = \"\"\n",
    "        count_vectors = f\"{count_vectors}\\n#{webindex[0]}\"\n",
    "        for k, v in output_dict.items():\n",
    "            count_vectors = f\"{count_vectors},{k}:{v}\"\n",
    "        # Append all the individual feature representative to global one\n",
    "        global_text.append(count_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using TFIDF Approach for generating feature vectors </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TFIDF for generating weighted feature representation\n",
    "\n",
    "def data_preprocessing(text):\n",
    "    reg = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "    filtered = [word for word in re.findall(reg, text.lower())]\n",
    "    with open(\"stopwords_en.txt\", \"r\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        # Remove the stopwords \n",
    "        stopwords = [line.replace('\\n', '') for line in stopwords]\n",
    "        filtered = [word for word in filtered if word not in stopwords]\n",
    "        return filtered\n",
    "    \n",
    "X = []\n",
    "X_title = []\n",
    "y_tfidf = []\n",
    "X_title_description = []\n",
    "\n",
    "for branch in [branches for branches in os.listdir('./data') if branches!='.DS_Store']:\n",
    "    for jd in os.listdir(f'./data/{branch}'):\n",
    "        y_tfidf.append(branch)\n",
    "        with open(os.path.join('./data', branch, jd), \"r\", encoding='utf-8') as f:\n",
    "            text_full = f.read()\n",
    "            # Fetch the job description from the file\n",
    "            text = text_full.split('Description: ', 1)[1]\n",
    "\n",
    "            # Fetch the title from the file\n",
    "            text_title = text_full.split('\\n')[0].split(\"Title: \")[1]\n",
    "            \n",
    "        filtered_text = data_preprocessing(text)\n",
    "        X.append(\" \".join(filtered_text))\n",
    "        filtered_title = data_preprocessing(text_title)\n",
    "        X_title.append(\" \".join(filtered_title))\n",
    "        filtered_title_description = filtered_text + filtered_title\n",
    "        X_title_description.append(\" \".join(filtered_title_description))\n",
    "\n",
    "        \n",
    "# Feature representation using TFIDF on description\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Feature representation using TFIDF on title\n",
    "X_tfidf_title = vectorizer.fit_transform(X_title)\n",
    "\n",
    "# Feature representation using TFIDF on title+description\n",
    "X_tfidf_title_description = vectorizer.fit_transform(X_title_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using Glove word embeddings for generating unweighted feature representation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = EmbeddingTransformer('glove')\n",
    "X_train_glove = glove.transform(X)\n",
    "X_train_title_glove = glove.transform(X_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs\n",
    "Save the count vector representation as per spectification.\n",
    "- count_vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the bag of words output to the disk\n",
    "with open('count_vectors.txt', 'w') as f:\n",
    "    f.write(\"\".join(global_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Job Advertisement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...... Sections and code blocks on buidling classification models based on different document feature represetations. \n",
    "Detailed comparsions and evaluations on different models to answer each question as per specification. \n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 01: Language model comparisons </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using Bag of words approach</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report using Logistic Regression Classifier\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.84      0.80      0.82        40\n",
      "       Engineering       0.85      0.91      0.88        43\n",
      "Healthcare_Nursing       0.97      0.85      0.90        39\n",
      "             Sales       0.71      0.79      0.75        34\n",
      "\n",
      "          accuracy                           0.84       156\n",
      "         macro avg       0.84      0.84      0.84       156\n",
      "      weighted avg       0.85      0.84      0.84       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the vocabulary file to count the number of features\n",
    "with open('vocab.txt') as f:\n",
    "    n_features = len(f.readlines()) + 1\n",
    "with open('count_vectors.txt') as f:\n",
    "    count_vectors = f.read()\n",
    "\n",
    "# Initialize pandas dataframe with features as columns and data points as rows\n",
    "df = pd.DataFrame(columns=[np.arange(0, n_features-1)])\n",
    "\n",
    "# Add all the data points in rows\n",
    "for i, row in enumerate(count_vectors.split('\\n')[1:]):\n",
    "    row = row.split(',')[1:]\n",
    "    for c in row: \n",
    "        df.loc[i, df[int(c.split(':')[0])]] = c.split(':')[1]\n",
    "        \n",
    "# Fill missing data with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=77)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Classification Report using Logistic Regression Classifier\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using TFIDF approach </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report using Logistic Regression Classifier\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.83      0.88      0.85        40\n",
      "       Engineering       0.85      0.95      0.90        43\n",
      "Healthcare_Nursing       1.00      0.87      0.93        39\n",
      "             Sales       0.88      0.82      0.85        34\n",
      "\n",
      "          accuracy                           0.88       156\n",
      "         macro avg       0.89      0.88      0.88       156\n",
      "      weighted avg       0.89      0.88      0.89       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_tfidf, test_size=0.2, random_state=77)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Classification Report using Logistic Regression Classifier\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using Glove Word Embeddings Approach </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report using Logistic Regression Classifier\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.73      0.82      0.78        40\n",
      "       Engineering       0.88      0.84      0.86        43\n",
      "Healthcare_Nursing       0.97      0.95      0.96        39\n",
      "             Sales       0.78      0.74      0.76        34\n",
      "\n",
      "          accuracy                           0.84       156\n",
      "         macro avg       0.84      0.84      0.84       156\n",
      "      weighted avg       0.84      0.84      0.84       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_glove, y_tfidf, test_size=0.2, random_state=77)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Classification Report using Logistic Regression Classifier\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> From the above results, we can see that the TFIDF generated feature vectors provided the best accuracy </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Q2: Does more information provide higher accuracy? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using K-Fold Validation for choosing best language model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Validation Scores:  [0.86538462 0.82580645 0.87741935 0.86451613 0.86451613]\n",
      "TFIDF Validation Scores:  [0.88461538 0.88387097 0.90322581 0.90322581 0.89032258]\n",
      "Glove Word Embeddings Validation Scores:  [0.78205128 0.76129032 0.7483871  0.81935484 0.77419355]\n"
     ]
    }
   ],
   "source": [
    "# On Bag of words\n",
    "scores = cross_val_score(lr, df, y, cv=5)\n",
    "print(\"Bag of Words Validation Scores: \", scores)\n",
    "\n",
    "# On TFIDF\n",
    "scores = cross_val_score(lr, X_tfidf, y_tfidf, cv=5)\n",
    "print(\"TFIDF Validation Scores: \", scores)\n",
    "\n",
    "# On Glove Word Embeddings\n",
    "scores = cross_val_score(lr, X_train_glove, y_tfidf, cv=5)\n",
    "print(\"Glove Word Embeddings Validation Scores: \",scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As we can see that the TFIDF provides the best scores, so we'll do further analysis using the TFIDF weighted vectors </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using only Job Title</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Using Title ********************\n",
      "Classification Report using Logistic Regression Classifier\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.86      0.90      0.88        40\n",
      "       Engineering       0.89      0.95      0.92        43\n",
      "Healthcare_Nursing       1.00      0.90      0.95        39\n",
      "             Sales       0.88      0.85      0.87        34\n",
      "\n",
      "          accuracy                           0.90       156\n",
      "         macro avg       0.91      0.90      0.90       156\n",
      "      weighted avg       0.91      0.90      0.90       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*20, \"Using Title\", \"*\"*20)\n",
    "\n",
    "# Splitting the dataset into train and test\n",
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(X_tfidf_title, y_tfidf, test_size=0.2, random_state=77)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Classification Report using Logistic Regression Classifier\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using only Job Description</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Using Description ********************\n",
      "Classification Report using Logistic Regression Classifier\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.83      0.88      0.85        40\n",
      "       Engineering       0.85      0.95      0.90        43\n",
      "Healthcare_Nursing       1.00      0.87      0.93        39\n",
      "             Sales       0.88      0.82      0.85        34\n",
      "\n",
      "          accuracy                           0.88       156\n",
      "         macro avg       0.89      0.88      0.88       156\n",
      "      weighted avg       0.89      0.88      0.89       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*20, \"Using Description\", \"*\"*20)\n",
    "# Splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_tfidf, test_size=0.2, random_state=77)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Classification Report using Logistic Regression Classifier\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Using Title & Description ********************\n",
      "Classification Report using Logistic Regression Classifier\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Accounting_Finance       0.84      0.90      0.87        40\n",
      "       Engineering       0.82      0.98      0.89        43\n",
      "Healthcare_Nursing       1.00      0.85      0.92        39\n",
      "             Sales       0.90      0.76      0.83        34\n",
      "\n",
      "          accuracy                           0.88       156\n",
      "         macro avg       0.89      0.87      0.88       156\n",
      "      weighted avg       0.89      0.88      0.88       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Title & Description combined\n",
    "print(\"*\"*20, \"Using Title & Description\", \"*\"*20)\n",
    "\n",
    "# Splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_title_description, y_tfidf, test_size=0.2, random_state=77)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train+X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Classification Report using Logistic Regression Classifier\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Summary\n",
    "In the above code blocks, for task 2 I have first generated the feature vectors of only the description using bag of words, TFIDF and Glvoe word embeddings, then I have applied Logistic Regression classfier on all three feature vectors and I found that the best performance (88%) was achieved using the TFIDF approach.\n",
    "\n",
    "For Task 3, first I have used K-flod Cross Validation on all three types of feature vectors to check which was the best one for further analysis and again TFIDF gave the best validation scores of around 90%, so, I used TFIDF first over only the title feature vectors, then on the description feature vectors and then on both of them combined to check whether adding more information has any effect on the accuracy. From the above results we can see that I got the best accuracy (90%) from using only the title feature vectors,  both of the other appraoches max. accuracy was 88%, so, from these results I can deduce that increasing the amount of information doesn't mean that the model will be more accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
